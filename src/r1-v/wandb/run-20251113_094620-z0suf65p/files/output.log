wandb: Detected [openai] in use.
wandb: Use W&B Weave for improved LLM call tracing. Install Weave with `pip install weave` then add `import weave` to the top of your script.
wandb: For more information, check out the docs at: https://weave-docs.wandb.ai/
  0%|          | 8/4678 [02:47<27:26:31, 21.15s/it]
Invalidate trace cache @ step 0 and module 2618: cache has only 0 modules
Invalidate trace cache @ step 0 and module 3927: cache has only 0 modules
[2025-11-13 09:46:45,781] [WARNING] [stage3.py:2114:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.0001, 'grad_norm': 6.180035324171268, 'learning_rate': 9.99786233433091e-07, 'completion_length': 167.6875, 'rewards/accuracy_reward': 0.28125, 'rewards/format_reward': 1.0, 'reward': 1.28125, 'reward_std': 0.38816186785697937, 'kl': 0.001384735107421875, 'epoch': 0.0}
Invalidate trace cache @ step 0 and module 5236: cache has only 0 modules
Invalidate trace cache @ step 0 and module 6545: cache has only 0 modules
[2025-11-13 09:47:06,194] [WARNING] [stage3.py:2114:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.0001, 'grad_norm': 5.261675751570984, 'learning_rate': 9.99572466866182e-07, 'completion_length': 167.8125, 'rewards/accuracy_reward': 0.25, 'rewards/format_reward': 1.0, 'reward': 1.25, 'reward_std': 0.2587745785713196, 'kl': 0.00164794921875, 'epoch': 0.0}
Invalidate trace cache @ step 0 and module 7854: cache has only 0 modules
Invalidate trace cache @ step 0 and module 9163: cache has only 0 modules
[2025-11-13 09:47:27,121] [WARNING] [stage3.py:2114:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.0001, 'grad_norm': 4.521971918344076, 'learning_rate': 9.99358700299273e-07, 'completion_length': 179.75, 'rewards/accuracy_reward': 0.6875, 'rewards/format_reward': 1.0, 'reward': 1.6875, 'reward_std': 0.2177756354212761, 'kl': 0.001377105712890625, 'epoch': 0.0}
Invalidate trace cache @ step 0 and module 10472: cache has only 0 modules
Invalidate trace cache @ step 0 and module 11781: cache has only 0 modules
[2025-11-13 09:47:46,847] [WARNING] [stage3.py:2114:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.0001, 'grad_norm': 6.877834585516894, 'learning_rate': 9.99144933732364e-07, 'completion_length': 196.75, 'rewards/accuracy_reward': 0.53125, 'rewards/format_reward': 1.0, 'reward': 1.53125, 'reward_std': 0.494472935795784, 'kl': 0.00146484375, 'epoch': 0.0}
Invalidate trace cache @ step 0 and module 13090: cache has only 0 modules
Invalidate trace cache @ step 0 and module 14399: cache has only 0 modules
[2025-11-13 09:48:09,806] [WARNING] [stage3.py:2114:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.0001, 'grad_norm': 5.838068552540004, 'learning_rate': 9.989311671654551e-07, 'completion_length': 200.03125, 'rewards/accuracy_reward': 0.4375, 'rewards/format_reward': 0.96875, 'reward': 1.40625, 'reward_std': 0.3808925598859787, 'kl': 0.001338958740234375, 'epoch': 0.0}
Invalidate trace cache @ step 0 and module 15708: cache has only 0 modules
Invalidate trace cache @ step 0 and module 17017: cache has only 0 modules
{'loss': 0.0001, 'grad_norm': 7.4164023264766925, 'learning_rate': 9.987174005985464e-07, 'completion_length': 158.84375, 'rewards/accuracy_reward': 0.3125, 'rewards/format_reward': 1.0, 'reward': 1.3125, 'reward_std': 0.4671337604522705, 'kl': 0.001739501953125, 'epoch': 0.0}
Invalidate trace cache @ step 0 and module 18326: cache has only 0 modules
Invalidate trace cache @ step 0 and module 19635: cache has only 0 modules
{'loss': 0.0001, 'grad_norm': 6.917808349005155, 'learning_rate': 9.985036340316374e-07, 'completion_length': 168.15625, 'rewards/accuracy_reward': 0.59375, 'rewards/format_reward': 1.0, 'reward': 1.59375, 'reward_std': 0.3198433816432953, 'kl': 0.001575469970703125, 'epoch': 0.0}
Invalidate trace cache @ step 0 and module 20944: cache has only 0 modules
Invalidate trace cache @ step 0 and module 22253: cache has only 0 modules
{'loss': 0.0001, 'grad_norm': 4.911091061570895, 'learning_rate': 9.982898674647285e-07, 'completion_length': 186.125, 'rewards/accuracy_reward': 0.125, 'rewards/format_reward': 1.0, 'reward': 1.125, 'reward_std': 0.2177756428718567, 'kl': 0.00130462646484375, 'epoch': 0.0}
Invalidate trace cache @ step 0 and module 23562: cache has only 0 modules
Invalidate trace cache @ step 0 and module 24871: cache has only 0 modules
[2025-11-13 09:49:30,061] [WARNING] [stage3.py:2114:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.0001, 'grad_norm': 6.155218179539678, 'learning_rate': 9.980761008978195e-07, 'completion_length': 169.9375, 'rewards/accuracy_reward': 0.5625, 'rewards/format_reward': 0.96875, 'reward': 1.53125, 'reward_std': 0.3377464711666107, 'kl': 0.001575469970703125, 'epoch': 0.0}
Invalidate trace cache @ step 0 and module 26180: cache has only 0 modules
Invalidate trace cache @ step 0 and module 27489: cache has only 0 modules
[2025-11-13 09:49:51,330] [WARNING] [stage3.py:2114:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.0001, 'grad_norm': 5.602119466766402, 'learning_rate': 9.978623343309105e-07, 'completion_length': 199.875, 'rewards/accuracy_reward': 0.34375, 'rewards/format_reward': 0.96875, 'reward': 1.3125, 'reward_std': 0.3335031569004059, 'kl': 0.00131988525390625, 'epoch': 0.0}
Invalidate trace cache @ step 0 and module 28798: cache has only 0 modules
Invalidate trace cache @ step 0 and module 30107: cache has only 0 modules
{'loss': 0.0001, 'grad_norm': 6.62882244382278, 'learning_rate': 9.976485677640016e-07, 'completion_length': 163.78125, 'rewards/accuracy_reward': 0.5, 'rewards/format_reward': 0.96875, 'reward': 1.46875, 'reward_std': 0.5123760402202606, 'kl': 0.0013580322265625, 'epoch': 0.0}
Invalidate trace cache @ step 0 and module 31416: cache has only 0 modules
Invalidate trace cache @ step 0 and module 32725: cache has only 0 modules
{'loss': 0.0001, 'grad_norm': 3.397329298491776, 'learning_rate': 9.974348011970928e-07, 'completion_length': 168.8125, 'rewards/accuracy_reward': 0.59375, 'rewards/format_reward': 1.0, 'reward': 1.59375, 'reward_std': 0.1293872892856598, 'kl': 0.001644134521484375, 'epoch': 0.01}
Invalidate trace cache @ step 0 and module 34034: cache has only 0 modules
Invalidate trace cache @ step 0 and module 35343: cache has only 0 modules
[2025-11-13 09:50:56,916] [WARNING] [stage3.py:2114:step] 5 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.0001, 'grad_norm': 3.0671442680070986, 'learning_rate': 9.972210346301839e-07, 'completion_length': 209.59375, 'rewards/accuracy_reward': 0.03125, 'rewards/format_reward': 1.0, 'reward': 1.03125, 'reward_std': 0.0883883461356163, 'kl': 0.001468658447265625, 'epoch': 0.01}
Invalidate trace cache @ step 0 and module 36652: cache has only 0 modules
Invalidate trace cache @ step 0 and module 37961: cache has only 0 modules
[2025-11-13 09:51:18,278] [WARNING] [stage3.py:2114:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.0001, 'grad_norm': 4.480821498571273, 'learning_rate': 9.970072680632749e-07, 'completion_length': 174.96875, 'rewards/accuracy_reward': 0.21875, 'rewards/format_reward': 1.0, 'reward': 1.21875, 'reward_std': 0.2630178928375244, 'kl': 0.0013885498046875, 'epoch': 0.01}
Invalidate trace cache @ step 0 and module 39270: cache has only 0 modules
Invalidate trace cache @ step 0 and module 40579: cache has only 0 modules
[2025-11-13 09:51:37,565] [WARNING] [stage3.py:2114:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.0001, 'grad_norm': 5.029544689806491, 'learning_rate': 9.96793501496366e-07, 'completion_length': 160.0, 'rewards/accuracy_reward': 0.28125, 'rewards/format_reward': 1.0, 'reward': 1.28125, 'reward_std': 0.2041158676147461, 'kl': 0.0018310546875, 'epoch': 0.01}
Invalidate trace cache @ step 0 and module 41888: cache has only 0 modules
Invalidate trace cache @ step 0 and module 43197: cache has only 0 modules
[2025-11-13 09:51:54,993] [WARNING] [stage3.py:2114:step] 4 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.0001, 'grad_norm': 6.391576533789416, 'learning_rate': 9.96579734929457e-07, 'completion_length': 170.40625, 'rewards/accuracy_reward': 0.6875, 'rewards/format_reward': 1.0, 'reward': 1.6875, 'reward_std': 0.3471825420856476, 'kl': 0.001811981201171875, 'epoch': 0.01}
Invalidate trace cache @ step 0 and module 44506: cache has only 0 modules
Invalidate trace cache @ step 0 and module 45815: cache has only 0 modules
[2025-11-13 09:52:18,203] [WARNING] [stage3.py:2114:step] 4 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.0001, 'grad_norm': 6.19484153058655, 'learning_rate': 9.96365968362548e-07, 'completion_length': 189.0625, 'rewards/accuracy_reward': 0.3125, 'rewards/format_reward': 1.0, 'reward': 1.3125, 'reward_std': 0.2925042137503624, 'kl': 0.00145721435546875, 'epoch': 0.01}
Invalidate trace cache @ step 0 and module 47124: cache has only 0 modules
Invalidate trace cache @ step 0 and module 48433: cache has only 0 modules
[2025-11-13 09:52:37,250] [WARNING] [stage3.py:2114:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.0001, 'grad_norm': 5.717191686039981, 'learning_rate': 9.96152201795639e-07, 'completion_length': 163.4375, 'rewards/accuracy_reward': 0.3125, 'rewards/format_reward': 1.0, 'reward': 1.3125, 'reward_std': 0.2177756354212761, 'kl': 0.00162506103515625, 'epoch': 0.01}
Invalidate trace cache @ step 0 and module 49742: cache has only 0 modules
Invalidate trace cache @ step 0 and module 51051: cache has only 0 modules
[2025-11-13 09:52:55,303] [WARNING] [stage3.py:2114:step] 4 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.0001, 'grad_norm': 6.131297514735297, 'learning_rate': 9.959384352287303e-07, 'completion_length': 165.9375, 'rewards/accuracy_reward': 0.4375, 'rewards/format_reward': 1.0, 'reward': 1.4375, 'reward_std': 0.3745020925998688, 'kl': 0.001811981201171875, 'epoch': 0.01}
Invalidate trace cache @ step 0 and module 52360: cache has only 0 modules
Invalidate trace cache @ step 0 and module 53669: cache has only 0 modules
[2025-11-13 09:53:14,162] [WARNING] [stage3.py:2114:step] 4 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.0001, 'grad_norm': 4.6605571212789725, 'learning_rate': 9.957246686618213e-07, 'completion_length': 161.28125, 'rewards/accuracy_reward': 0.125, 'rewards/format_reward': 1.0, 'reward': 1.125, 'reward_std': 0.2177756428718567, 'kl': 0.00167083740234375, 'epoch': 0.01}
Invalidate trace cache @ step 0 and module 54978: cache has only 0 modules
Invalidate trace cache @ step 0 and module 56287: cache has only 0 modules
[2025-11-13 09:53:34,780] [WARNING] [stage3.py:2114:step] 4 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.0001, 'grad_norm': 6.800436125365715, 'learning_rate': 9.955109020949124e-07, 'completion_length': 185.75, 'rewards/accuracy_reward': 0.5, 'rewards/format_reward': 1.0, 'reward': 1.5, 'reward_std': 0.1767766922712326, 'kl': 0.0020599365234375, 'epoch': 0.01}
Invalidate trace cache @ step 0 and module 57596: cache has only 0 modules
Invalidate trace cache @ step 0 and module 58905: cache has only 0 modules
[2025-11-13 09:53:52,502] [WARNING] [stage3.py:2114:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.0001, 'grad_norm': 6.061405279991887, 'learning_rate': 9.952971355280034e-07, 'completion_length': 160.34375, 'rewards/accuracy_reward': 0.3125, 'rewards/format_reward': 1.0, 'reward': 1.3125, 'reward_std': 0.3471825420856476, 'kl': 0.00189971923828125, 'epoch': 0.01}
Invalidate trace cache @ step 0 and module 60214: cache has only 0 modules
Invalidate trace cache @ step 0 and module 61523: cache has only 0 modules
[2025-11-13 09:54:10,518] [WARNING] [stage3.py:2114:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.0001, 'grad_norm': 7.174335700697164, 'learning_rate': 9.950833689610944e-07, 'completion_length': 179.90625, 'rewards/accuracy_reward': 0.5625, 'rewards/format_reward': 1.0, 'reward': 1.5625, 'reward_std': 0.3945523351430893, 'kl': 0.001857757568359375, 'epoch': 0.01}
Invalidate trace cache @ step 0 and module 62832: cache has only 0 modules
Invalidate trace cache @ step 0 and module 64141: cache has only 0 modules
[2025-11-13 09:54:30,514] [WARNING] [stage3.py:2114:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.0001, 'grad_norm': 5.924613921671379, 'learning_rate': 9.948696023941855e-07, 'completion_length': 179.6875, 'rewards/accuracy_reward': 0.65625, 'rewards/format_reward': 0.96875, 'reward': 1.625, 'reward_std': 0.3745020925998688, 'kl': 0.00206756591796875, 'epoch': 0.01}
Invalidate trace cache @ step 0 and module 65450: cache has only 0 modules
Invalidate trace cache @ step 0 and module 66759: cache has only 0 modules
{'loss': 0.0001, 'grad_norm': 5.553938120631901, 'learning_rate': 9.946558358272765e-07, 'completion_length': 153.78125, 'rewards/accuracy_reward': 0.3125, 'rewards/format_reward': 1.0, 'reward': 1.3125, 'reward_std': 0.1767766922712326, 'kl': 0.00197601318359375, 'epoch': 0.01}
Invalidate trace cache @ step 0 and module 68068: cache has only 0 modules
Invalidate trace cache @ step 0 and module 69377: cache has only 0 modules
[2025-11-13 09:55:07,451] [WARNING] [stage3.py:2114:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.0001, 'grad_norm': 6.184245315297548, 'learning_rate': 9.944420692603678e-07, 'completion_length': 169.96875, 'rewards/accuracy_reward': 0.625, 'rewards/format_reward': 1.0, 'reward': 1.625, 'reward_std': 0.2925042137503624, 'kl': 0.002349853515625, 'epoch': 0.01}
Invalidate trace cache @ step 0 and module 70686: cache has only 0 modules
Invalidate trace cache @ step 0 and module 71995: cache has only 0 modules
[2025-11-13 09:55:26,535] [WARNING] [stage3.py:2114:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.0001, 'grad_norm': 5.445910684907284, 'learning_rate': 9.942283026934588e-07, 'completion_length': 176.53125, 'rewards/accuracy_reward': 0.375, 'rewards/format_reward': 1.0, 'reward': 1.375, 'reward_std': 0.3335031569004059, 'kl': 0.00215911865234375, 'epoch': 0.01}
Invalidate trace cache @ step 0 and module 73304: cache has only 0 modules
Invalidate trace cache @ step 0 and module 74613: cache has only 0 modules
[2025-11-13 09:55:44,306] [WARNING] [stage3.py:2114:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.0001, 'grad_norm': 6.937056111359408, 'learning_rate': 9.940145361265498e-07, 'completion_length': 159.875, 'rewards/accuracy_reward': 0.6875, 'rewards/format_reward': 1.0, 'reward': 1.6875, 'reward_std': 0.44403791427612305, 'kl': 0.0019683837890625, 'epoch': 0.01}
Invalidate trace cache @ step 0 and module 75922: cache has only 0 modules
Invalidate trace cache @ step 0 and module 77231: cache has only 0 modules
[2025-11-13 09:56:00,695] [WARNING] [stage3.py:2114:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.0001, 'grad_norm': 6.609947008236573, 'learning_rate': 9.938007695596409e-07, 'completion_length': 159.96875, 'rewards/accuracy_reward': 0.53125, 'rewards/format_reward': 1.0, 'reward': 1.53125, 'reward_std': 0.4628904461860657, 'kl': 0.00186920166015625, 'epoch': 0.01}
Invalidate trace cache @ step 0 and module 78540: cache has only 0 modules
Invalidate trace cache @ step 0 and module 79849: cache has only 0 modules
{'loss': 0.0001, 'grad_norm': 5.3295752647131875, 'learning_rate': 9.93587002992732e-07, 'completion_length': 153.6875, 'rewards/accuracy_reward': 0.3125, 'rewards/format_reward': 1.0, 'reward': 1.3125, 'reward_std': 0.2587745785713196, 'kl': 0.00225067138671875, 'epoch': 0.01}
Invalidate trace cache @ step 0 and module 81158: cache has only 0 modules
Invalidate trace cache @ step 0 and module 82467: cache has only 0 modules
[2025-11-13 09:56:39,136] [WARNING] [stage3.py:2114:step] 4 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.0001, 'grad_norm': 6.631395745700858, 'learning_rate': 9.93373236425823e-07, 'completion_length': 203.84375, 'rewards/accuracy_reward': 0.53125, 'rewards/format_reward': 1.0, 'reward': 1.53125, 'reward_std': 0.4534740000963211, 'kl': 0.00225067138671875, 'epoch': 0.01}
Invalidate trace cache @ step 0 and module 83776: cache has only 0 modules
Invalidate trace cache @ step 0 and module 85085: cache has only 0 modules
[2025-11-13 09:57:00,915] [WARNING] [stage3.py:2114:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.0001, 'grad_norm': 3.167611740428525, 'learning_rate': 9.93159469858914e-07, 'completion_length': 165.59375, 'rewards/accuracy_reward': 0.375, 'rewards/format_reward': 1.0, 'reward': 1.375, 'reward_std': 0.13363061845302582, 'kl': 0.0021820068359375, 'epoch': 0.01}
Invalidate trace cache @ step 0 and module 86394: cache has only 0 modules
Invalidate trace cache @ step 0 and module 87703: cache has only 0 modules
[2025-11-13 09:57:22,843] [WARNING] [stage3.py:2114:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.0001, 'grad_norm': 4.459758797835315, 'learning_rate': 9.92945703292005e-07, 'completion_length': 180.3125, 'rewards/accuracy_reward': 0.15625, 'rewards/format_reward': 0.96875, 'reward': 1.125, 'reward_std': 0.2925042062997818, 'kl': 0.00237274169921875, 'epoch': 0.01}
Invalidate trace cache @ step 0 and module 89012: cache has only 0 modules
Invalidate trace cache @ step 0 and module 90321: cache has only 0 modules
{'loss': 0.0001, 'grad_norm': 5.734909962768204, 'learning_rate': 9.92731936725096e-07, 'completion_length': 175.9375, 'rewards/accuracy_reward': 0.625, 'rewards/format_reward': 1.0, 'reward': 1.625, 'reward_std': 0.3335031494498253, 'kl': 0.002166748046875, 'epoch': 0.01}
Invalidate trace cache @ step 0 and module 91630: cache has only 0 modules
Invalidate trace cache @ step 0 and module 92939: cache has only 0 modules
{'loss': 0.0001, 'grad_norm': 6.5577279676171365, 'learning_rate': 9.92518170158187e-07, 'completion_length': 162.5, 'rewards/accuracy_reward': 0.25, 'rewards/format_reward': 1.0, 'reward': 1.25, 'reward_std': 0.3335031494498253, 'kl': 0.0027618408203125, 'epoch': 0.01}
Invalidate trace cache @ step 0 and module 94248: cache has only 0 modules
Invalidate trace cache @ step 0 and module 95557: cache has only 0 modules
{'loss': 0.0001, 'grad_norm': 6.200100065864131, 'learning_rate': 9.923044035912783e-07, 'completion_length': 167.96875, 'rewards/accuracy_reward': 0.125, 'rewards/format_reward': 0.96875, 'reward': 1.09375, 'reward_std': 0.22201895713806152, 'kl': 0.0025482177734375, 'epoch': 0.02}
Invalidate trace cache @ step 0 and module 96866: cache has only 0 modules
Invalidate trace cache @ step 0 and module 98175: cache has only 0 modules
[2025-11-13 09:58:34,831] [WARNING] [stage3.py:2114:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.0001, 'grad_norm': 7.620393959603448, 'learning_rate': 9.920906370243694e-07, 'completion_length': 144.5, 'rewards/accuracy_reward': 0.40625, 'rewards/format_reward': 0.96875, 'reward': 1.375, 'reward_std': 0.5081326961517334, 'kl': 0.00244140625, 'epoch': 0.02}
Invalidate trace cache @ step 0 and module 99484: cache has only 0 modules
Invalidate trace cache @ step 0 and module 100793: cache has only 0 modules
[2025-11-13 09:58:52,568] [WARNING] [stage3.py:2114:step] 2 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.0001, 'grad_norm': 7.655549849177174, 'learning_rate': 9.918768704574604e-07, 'completion_length': 171.25, 'rewards/accuracy_reward': 0.625, 'rewards/format_reward': 1.0, 'reward': 1.625, 'reward_std': 0.5081327110528946, 'kl': 0.0029449462890625, 'epoch': 0.02}
Invalidate trace cache @ step 0 and module 102102: cache has only 0 modules
Invalidate trace cache @ step 0 and module 103411: cache has only 0 modules
[2025-11-13 09:59:16,023] [WARNING] [stage3.py:2114:step] 3 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
{'loss': 0.0001, 'grad_norm': 7.589061673606686, 'learning_rate': 9.916631038905514e-07, 'completion_length': 170.625, 'rewards/accuracy_reward': 0.34375, 'rewards/format_reward': 1.0, 'reward': 1.34375, 'reward_std': 0.47137708961963654, 'kl': 0.00257110595703125, 'epoch': 0.02}
Invalidate trace cache @ step 0 and module 104720: cache has only 0 modules
Invalidate trace cache @ step 0 and module 106029: cache has only 0 modules
